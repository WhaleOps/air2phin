migration:
  # ---------------------------------------------
  # Different version of airflow import statement
  # ---------------------------------------------
  # airflow.operators.spark_sql_operator
  simple_bare_sql:
    src: |
      from airflow.operators.spark_sql_operator import SparkSqlOperator
      
      bash = SparkSqlOperator(
          task_id='spark-sql',
          conn_id='spark_default_conn',
          sql='select * from table',
      )
    dest: |
      from pydolphinschsduler.tasks.sql import Sql
      
      bash = Sql(
          name='spark-sql',
          datasource_name='spark_default_conn',
          sql='select * from table',
      )
  simple_sql_file:
    src: |
      from airflow.operators.spark_sql_operator import SparkSqlOperator
      
      bash = SparkSqlOperator(
          task_id='spark-sql',
          conn_id='spark_default_conn',
          sql='test.sql',
      )
    dest: |
      from pydolphinschsduler.tasks.sql import Sql
      
      bash = Sql(
          name='spark-sql',
          datasource_name='spark_default_conn',
          sql='test.sql',
      )
